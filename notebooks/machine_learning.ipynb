{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import tempfile\n",
    "import IPython.display\n",
    "import pathlib\n",
    "\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "import sklearn.impute\n",
    "import sklearn.ensemble\n",
    "import sklearn.pipeline\n",
    "import sklearn.tree\n",
    "import sklearn.metrics\n",
    "import sklearn.neural_network\n",
    "\n",
    "import ml_colon\n",
    "import ml_colon.data_preparation\n",
    "import ml_colon.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving Data\n",
    "\n",
    "We have implemented the data cleaning the `ml_colon.data_preparation` module and with that retrieve the \"cleaned\" DataFrame. By \"cleaned\" we mean that we have filtered out all rows that we want to exclude from training. No further rows will be excluded from here onwards. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ml_colon.data_preparation.get_clean_df_from_csv()\n",
    "\n",
    "print(f\"Loaded data set with {len(df)} rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Train / Test set\n",
    "\n",
    "Next we split the data set into the train / test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2 # 20% of rows\n",
    "features = [c for c in df.columns if c != ml_colon.TARGET_VARIABLE]\n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "    df[features],\n",
    "    df[ml_colon.TARGET_VARIABLE],\n",
    "    test_size=test_size,\n",
    "    random_state=ml_colon.SEED,\n",
    ")\n",
    "\n",
    "print(f\"Train set: {len(y_train)} rows | Test set: {len(y_test)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers and Parameters Definition\n",
    "We will try different models to get the best outcome with different hyperparameters based on the accuracy of the model. The different classifiers used are: \n",
    "\n",
    "- K-Nearest Neighbor\n",
    "- Random Forest \n",
    "- Multi-Layer Perceptron\n",
    "\n",
    "With this selection, there is a variety of complexity of models used. There is one simple model, namely the K-Nearest Neighbor algorithm. The Random Forest algorithm is an ensemble method and a more powerful method than K-Nearest Neighbors. Nowadays, there is a big hype around neural networks and their power of finding interesting patterns in data, therefore the Multi-Layer Perceptron is included. \n",
    "\n",
    "Each of these algorithms will be tested with different hyperparameters using grid search. The different values of the parameters are described below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_metric = \"accuracy\"\n",
    "assert score_metric in ml_colon.SCORE_METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "implemented_classifiers = {\n",
    "    \"k_neighbor\": {\n",
    "        \"classifier\": sklearn.neighbors.KNeighborsClassifier(),\n",
    "        \"param_grid\": [{\"classifier__n_neighbors\": [5, 11, 15]}],\n",
    "    },\n",
    "    \"random_forest\": {\n",
    "        \"classifier\": sklearn.ensemble.RandomForestClassifier(max_features=2),\n",
    "        \"param_grid\": [{\"classifier__max_depth\": [4, 8, 10], \"classifier__n_estimators\": [10, 15, 20]}],\n",
    "    },\n",
    "    \"multilayer_perceptron\": {\n",
    "        \"classifier\": sklearn.neural_network.MLPClassifier(),\n",
    "        \"param_grid\": [\n",
    "            {\"classifier__alpha\": [0.001, 0.01, 0.1, 0.5], \"classifier__activation\": [\"identity\", \"relu\"]}\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "\n",
    "classifier = \"k_neighbor\"\n",
    "assert classifier in implemented_classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Pipeline\n",
    "\n",
    "Before a machine learning model can be trained some data transformations need to be done. For that we use a `sklearn.pipeline.Pipeline` to chain the data transformations such as imputing missing values or scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = sklearn.pipeline.Pipeline(\n",
    "    steps=[\n",
    "        (\n",
    "            \"impute_nan\",\n",
    "            sklearn.impute.SimpleImputer(missing_values=np.nan, strategy=\"mean\"),\n",
    "        ),\n",
    "        (\n",
    "            \"classifier\",\n",
    "            implemented_classifiers[classifier][\"classifier\"],\n",
    "        ),  # easy to extend with scalers, etc.\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_cv = sklearn.model_selection.GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=implemented_classifiers[classifier][\"param_grid\"],\n",
    "    scoring=score_metric,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation \n",
    "\n",
    "We use [mlflow](https://www.mlflow.org/) library to track each model training and save the resulting plots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"file://\" + str(ml_colon.OUTPUT_DIR / \"mlruns\"))\n",
    "tracking_uri = mlflow.get_tracking_uri()\n",
    "print(\"Current tracking uri: {}\".format(tracking_uri)) # where the outputs are stored\n",
    "\n",
    "mlflow.set_experiment(\"ml_colon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run() as run:\n",
    "\n",
    "    print(f\"Starting MlFlow run: {run.info.run_id}\", \"\\n\")\n",
    "    mlflow.log_param(\"classifier\", classifier)\n",
    "\n",
    "    # The training of the model\n",
    "    print(f\"Training a {classifier} classifier\")\n",
    "    classifier_cv.fit(X_train, y_train)\n",
    "\n",
    "    # Best parameters\n",
    "    print(\"Best parameters:\")\n",
    "    print(classifier_cv.best_params_, \"\\n\")\n",
    "\n",
    "    mlflow.log_params(classifier_cv.best_params_)\n",
    "    mlflow.log_metric(score_metric, classifier_cv.best_score_)\n",
    "\n",
    "    # Evaluation of results\n",
    "    print(\"Classification Report\")\n",
    "    y_pred = classifier_cv.predict(X_test)\n",
    "    y_pred_proba = classifier_cv.predict_proba(X_test)\n",
    "    report = sklearn.metrics.classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "    IPython.display.display(pd.DataFrame(report).T)\n",
    "\n",
    "    for label in [\"0.0\", \"1.0\"]:\n",
    "        for k, v in report[label].items():\n",
    "            mlflow.log_metric(f\"label_{label}_{k}\", v)\n",
    "\n",
    "\n",
    "    print(\"Plotting Confusion Matrix\")\n",
    "    cm = sklearn.metrics.confusion_matrix(y_test, y_pred)\n",
    "    cm_fig = sklearn.metrics.ConfusionMatrixDisplay(cm).plot()\n",
    "\n",
    "    print(\"Plotting ROC curve\")\n",
    "    roc_fig = sklearn.metrics.plot_roc_curve(\n",
    "        classifier_cv, X_test, y_test, name=\"ROC Curve\"\n",
    "    )\n",
    "\n",
    "    print(\"Writing Artifacts to MlFlow\")\n",
    "    with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "        tmp_dir_path = pathlib.Path(tmp_dir)\n",
    "        assert tmp_dir_path.exists()\n",
    "\n",
    "        cm_fig.figure_.savefig(str(tmp_dir_path / \"confusion_matrix.png\"))\n",
    "        roc_fig.figure_.savefig(str(tmp_dir_path / \"roc.png\"))\n",
    "\n",
    "        mlflow.log_artifacts(str(tmp_dir_path), artifact_path=\"plots\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MlFlow Dashboard\n",
    "\n",
    "As explained in the `README.md` you can now run the MlFlow dashboard by executing\n",
    "```\n",
    "cd output/\n",
    "mlflow ui\n",
    "```\n",
    "and then accessing the dashboard through your browser `http://127.0.0.1:5000`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('ml_colon': conda)",
   "metadata": {
    "interpreter": {
     "hash": "9185164058249c32e982ca89960c89434de45a89c9b6902cf1e69de00a5a7528"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
